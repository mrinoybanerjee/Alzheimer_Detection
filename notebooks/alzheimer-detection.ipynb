{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Alzheimer Detection"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:19:04.512441Z","iopub.status.busy":"2024-02-17T23:19:04.512047Z","iopub.status.idle":"2024-02-17T23:19:19.965354Z","shell.execute_reply":"2024-02-17T23:19:19.963977Z","shell.execute_reply.started":"2024-02-17T23:19:04.512409Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n","  warnings.warn(\n","/Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: efficientnet_pytorch in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (0.7.1)\n","Requirement already satisfied: torch in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from efficientnet_pytorch) (2.1.0)\n","Requirement already satisfied: filelock in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from torch->efficientnet_pytorch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from torch->efficientnet_pytorch) (4.8.0)\n","Requirement already satisfied: sympy in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from torch->efficientnet_pytorch) (1.12)\n","Requirement already satisfied: networkx in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from torch->efficientnet_pytorch) (3.2.1)\n","Requirement already satisfied: jinja2 in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from torch->efficientnet_pytorch) (3.1.2)\n","Requirement already satisfied: fsspec in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from torch->efficientnet_pytorch) (2023.10.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n","\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n","Defaulting to user installation because normal site-packages is not writeable\n","\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: timm in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (0.9.12)\n","Requirement already satisfied: torch>=1.7 in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from timm) (2.1.0)\n","Requirement already satisfied: torchvision in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from timm) (0.16.0)\n","Requirement already satisfied: pyyaml in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from timm) (0.20.3)\n","Requirement already satisfied: safetensors in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from timm) (0.4.2)\n","Requirement already satisfied: filelock in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from torch>=1.7->timm) (3.13.1)\n","Requirement already satisfied: typing-extensions in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from torch>=1.7->timm) (4.8.0)\n","Requirement already satisfied: sympy in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from torch>=1.7->timm) (1.12)\n","Requirement already satisfied: networkx in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from torch>=1.7->timm) (3.2.1)\n","Requirement already satisfied: jinja2 in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: fsspec in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from torch>=1.7->timm) (2023.10.0)\n","Requirement already satisfied: requests in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from huggingface-hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from huggingface-hub->timm) (4.66.1)\n","Requirement already satisfied: packaging>=20.9 in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from huggingface-hub->timm) (23.1)\n","Requirement already satisfied: numpy in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from torchvision->timm) (1.23.5)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from torchvision->timm) (10.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub->timm) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub->timm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub->timm) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n","\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/mrinoybanerjee/Library/Python/3.9/lib/python/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["import torch\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader, random_split\n","from torch import nn, optim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n","import itertools\n","import torch\n","%pip install efficientnet_pytorch\n","%pip install timm\n","from efficientnet_pytorch import EfficientNet\n","\n","# Set the device to GPU if available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocess Data"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:28:30.353785Z","iopub.status.busy":"2024-02-17T23:28:30.353076Z","iopub.status.idle":"2024-02-17T23:28:31.221814Z","shell.execute_reply":"2024-02-17T23:28:31.220844Z","shell.execute_reply.started":"2024-02-17T23:28:30.353750Z"},"trusted":true},"outputs":[],"source":["# Define the directory where the data is stored\n","# Replace with the path to your dataset\n","data_dir = '/Users/mrinoybanerjee/Desktop/Duke/Misc/Alzheimer_Detection/data/Dataset'\n","\n","# Define transforms for the data\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(10),\n","    transforms.RandomVerticalFlip(),\n","    transforms.RandomGrayscale(p=0.1),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","# Load the dataset with ImageFolder\n","dataset = datasets.ImageFolder(data_dir, transform=transform)\n","\n","#with wandb.init(project='wound-detection'):\n","# Split the dataset into train and validation sets\n","train_size = int(0.8 * len(dataset))  # 80% of dataset\n","val_size = len(dataset) - train_size  # 20% of dataset\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","# Create dataloaders\n","trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","valloader = DataLoader(val_dataset, batch_size=32, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Mean model: CNN"]},{"cell_type":"markdown","metadata":{},"source":["### Defining CNN architecture"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:20:24.587515Z","iopub.status.busy":"2024-02-17T23:20:24.586834Z","iopub.status.idle":"2024-02-17T23:20:25.141577Z","shell.execute_reply":"2024-02-17T23:20:25.140784Z","shell.execute_reply.started":"2024-02-17T23:20:24.587486Z"},"trusted":true},"outputs":[],"source":["# # Load a pre-trained model (e.g., ResNet18) and modify it for our task\n","model = models.resnet50(pretrained=True)\n","\n","# Freeze all the layers in the pretrained model\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# Replace the final layer with a new one that matches our number of classes (4 classes in our case)\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 4) \n","\n","# Move the model to the GPU if available\n","model = model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["### Specify loss function and optimizer"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:20:32.925077Z","iopub.status.busy":"2024-02-17T23:20:32.923850Z","iopub.status.idle":"2024-02-17T23:20:32.929890Z","shell.execute_reply":"2024-02-17T23:20:32.928970Z","shell.execute_reply.started":"2024-02-17T23:20:32.925040Z"},"trusted":true},"outputs":[],"source":["# Define the loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Define the optimizer, only optimizing the parameters of the final layer\n","optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{},"source":["### Train the model"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:20:36.107078Z","iopub.status.busy":"2024-02-17T23:20:36.106392Z","iopub.status.idle":"2024-02-17T23:27:27.614093Z","shell.execute_reply":"2024-02-17T23:27:27.613105Z","shell.execute_reply.started":"2024-02-17T23:20:36.107050Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 0.993020810931921\n","Validation Loss: 0.8811052426695823, Accuracy: 59.765625%\n","Epoch 2, Loss: 0.946183730661869\n","Validation Loss: 0.9558319568634033, Accuracy: 53.671875%\n","Epoch 3, Loss: 0.9394334770739079\n","Validation Loss: 0.8506219387054443, Accuracy: 61.5625%\n","Epoch 4, Loss: 0.9156592570245266\n","Validation Loss: 0.9193277403712272, Accuracy: 59.140625%\n","Epoch 5, Loss: 0.9161662645637989\n","Validation Loss: 0.8689188227057457, Accuracy: 59.6875%\n","Epoch 6, Loss: 0.9053775433450937\n","Validation Loss: 0.933951972424984, Accuracy: 56.328125%\n","Epoch 7, Loss: 0.9469131220132112\n","Validation Loss: 0.8426084518432617, Accuracy: 60.78125%\n","Epoch 8, Loss: 0.9161810997873545\n","Validation Loss: 0.8578127354383469, Accuracy: 58.359375%\n","Epoch 9, Loss: 0.9212848201394082\n","Validation Loss: 0.8325972512364388, Accuracy: 61.5625%\n","Epoch 10, Loss: 0.8958667729049921\n","Validation Loss: 0.8151761502027511, Accuracy: 61.5625%\n"]}],"source":["# Number of epochs to train for\n","num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    model.train()  # Set the model to training mode\n","    running_loss = 0.0\n","    \n","    for inputs, labels in trainloader:\n","        # Move the input and label tensors to the correct device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        \n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","        \n","        # Forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item()\n","    \n","    # Print statistics\n","    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n","    \n","    # Validation loss\n","    model.eval()  # Set the model to evaluation mode\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in valloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    \n","    print(f'Validation Loss: {val_loss / len(valloader)}, Accuracy: {100 * correct / total}%')\n","torch.save(model.state_dict(), '/kaggle/working/alzheimer_cnn_model.pth')\n","    "]},{"cell_type":"markdown","metadata":{},"source":["## EfficientNet for improved performance"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:27:36.543735Z","iopub.status.busy":"2024-02-17T23:27:36.543340Z","iopub.status.idle":"2024-02-17T23:27:37.400657Z","shell.execute_reply":"2024-02-17T23:27:37.399761Z","shell.execute_reply.started":"2024-02-17T23:27:36.543705Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n","100%|██████████| 20.4M/20.4M [00:00<00:00, 264MB/s]"]},{"name":"stdout","output_type":"stream","text":["Loaded pretrained weights for efficientnet-b0\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["efficientnet_model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=4)\n","\n","# Move the model to the GPU if available\n","efficientnet_model = efficientnet_model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["### Specify optimizer"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:28:41.708328Z","iopub.status.busy":"2024-02-17T23:28:41.707655Z","iopub.status.idle":"2024-02-17T23:28:41.713988Z","shell.execute_reply":"2024-02-17T23:28:41.713055Z","shell.execute_reply.started":"2024-02-17T23:28:41.708295Z"},"trusted":true},"outputs":[],"source":["optimizer = optim.Adam(efficientnet_model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{},"source":["### Train model"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:28:44.927992Z","iopub.status.busy":"2024-02-17T23:28:44.927168Z","iopub.status.idle":"2024-02-17T23:37:16.580237Z","shell.execute_reply":"2024-02-17T23:37:16.579289Z","shell.execute_reply.started":"2024-02-17T23:28:44.927958Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 0.8980784948915244\n","Validation Loss: 0.8724591717123985, Accuracy: 61.171875%\n","Epoch 2, Loss: 0.7276266282424331\n","Validation Loss: 0.762640118598938, Accuracy: 67.8125%\n","Epoch 3, Loss: 0.606681371293962\n","Validation Loss: 0.8390527710318565, Accuracy: 69.0625%\n","Epoch 4, Loss: 0.48915090300142766\n","Validation Loss: 1.66525459587574, Accuracy: 55.546875%\n","Epoch 5, Loss: 0.38152050408534705\n","Validation Loss: 0.6603597700595856, Accuracy: 78.75%\n","Epoch 6, Loss: 0.30560035733506086\n","Validation Loss: 0.45492283534258604, Accuracy: 84.140625%\n","Epoch 7, Loss: 0.23895487039117141\n","Validation Loss: 0.43397864773869516, Accuracy: 84.84375%\n","Epoch 8, Loss: 0.218417262728326\n","Validation Loss: 0.64566386975348, Accuracy: 76.25%\n","Epoch 9, Loss: 0.17739688321016728\n","Validation Loss: 0.3027012901380658, Accuracy: 90.078125%\n","Epoch 10, Loss: 0.15248490085359662\n","Validation Loss: 1.4890223354101182, Accuracy: 71.484375%\n"]}],"source":["# Number of epochs to train for\n","num_epochs = 10\n","\n","# train efficientnet model\n","for epoch in range(num_epochs):\n","    efficientnet_model.train()  # Set the model to training mode\n","    running_loss = 0.0\n","    \n","    for inputs, labels in trainloader:\n","        # Move the input and label tensors to the correct device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        \n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","        \n","        # Forward pass\n","        outputs = efficientnet_model(inputs)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item()\n","    \n","    # Print statistics\n","    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n","    \n","    # Validation loss\n","    efficientnet_model.eval()  # Set the model to evaluation mode\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in valloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = efficientnet_model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    \n","    print(f'Validation Loss: {val_loss / len(valloader)}, Accuracy: {100 * correct / total}%')\n","\n","# Save the model\n","    \n","torch.save(efficientnet_model.state_dict(), '/kaggle/working/alzheimer_efficientnet_model.pth')\n"]},{"cell_type":"markdown","metadata":{},"source":["## Vision Transformer for improved performance"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:42:07.476557Z","iopub.status.busy":"2024-02-17T23:42:07.476144Z","iopub.status.idle":"2024-02-17T23:42:14.203617Z","shell.execute_reply":"2024-02-17T23:42:14.202788Z","shell.execute_reply.started":"2024-02-17T23:42:07.476522Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/facebookresearch/deit/zipball/main\" to /root/.cache/torch/hub/main.zip\n","/root/.cache/torch/hub/facebookresearch_deit_main/models.py:63: UserWarning: Overwriting deit_tiny_patch16_224 in registry with models.deit_tiny_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  def deit_tiny_patch16_224(pretrained=False, **kwargs):\n","/root/.cache/torch/hub/facebookresearch_deit_main/models.py:78: UserWarning: Overwriting deit_small_patch16_224 in registry with models.deit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  def deit_small_patch16_224(pretrained=False, **kwargs):\n","/root/.cache/torch/hub/facebookresearch_deit_main/models.py:93: UserWarning: Overwriting deit_base_patch16_224 in registry with models.deit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  def deit_base_patch16_224(pretrained=False, **kwargs):\n","/root/.cache/torch/hub/facebookresearch_deit_main/models.py:108: UserWarning: Overwriting deit_tiny_distilled_patch16_224 in registry with models.deit_tiny_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  def deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):\n","/root/.cache/torch/hub/facebookresearch_deit_main/models.py:123: UserWarning: Overwriting deit_small_distilled_patch16_224 in registry with models.deit_small_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  def deit_small_distilled_patch16_224(pretrained=False, **kwargs):\n","/root/.cache/torch/hub/facebookresearch_deit_main/models.py:138: UserWarning: Overwriting deit_base_distilled_patch16_224 in registry with models.deit_base_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  def deit_base_distilled_patch16_224(pretrained=False, **kwargs):\n","/root/.cache/torch/hub/facebookresearch_deit_main/models.py:153: UserWarning: Overwriting deit_base_patch16_384 in registry with models.deit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  def deit_base_patch16_384(pretrained=False, **kwargs):\n","/root/.cache/torch/hub/facebookresearch_deit_main/models.py:168: UserWarning: Overwriting deit_base_distilled_patch16_384 in registry with models.deit_base_distilled_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  def deit_base_distilled_patch16_384(pretrained=False, **kwargs):\n","Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth\" to /root/.cache/torch/hub/checkpoints/deit_base_patch16_224-b5f2ef4d.pth\n","100%|██████████| 330M/330M [00:02<00:00, 152MB/s]  \n"]}],"source":["# Load a pre-trained Vision Transformer model\n","vit_model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n","\n","# Move the model to the GPU if available\n","vit_model = vit_model.to(device)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Define loss function and optimizer"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:42:42.027057Z","iopub.status.busy":"2024-02-17T23:42:42.026716Z","iopub.status.idle":"2024-02-17T23:42:42.033454Z","shell.execute_reply":"2024-02-17T23:42:42.032563Z","shell.execute_reply.started":"2024-02-17T23:42:42.027031Z"},"trusted":true},"outputs":[],"source":["# Define the optimizer, only optimizing the parameters of the final layer\n","optimizer = optim.Adam(vit_model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{},"source":["### Train Model"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:42:44.773964Z","iopub.status.busy":"2024-02-17T23:42:44.773620Z","iopub.status.idle":"2024-02-18T00:04:04.352295Z","shell.execute_reply":"2024-02-18T00:04:04.351154Z","shell.execute_reply.started":"2024-02-17T23:42:44.773939Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 1.1634845238178968\n","Validation Loss: 1.0732713043689728, Accuracy: 32.1875%\n","Epoch 2, Loss: 1.0529922910034657\n","Validation Loss: 1.0259643480181695, Accuracy: 53.359375%\n","Epoch 3, Loss: 1.0125707723200321\n","Validation Loss: 0.8805326148867607, Accuracy: 56.25%\n","Epoch 4, Loss: 1.0047540474683045\n","Validation Loss: 0.9534257456660271, Accuracy: 53.59375%\n","Epoch 5, Loss: 0.9667909078299999\n","Validation Loss: 0.8876874297857285, Accuracy: 55.703125%\n","Epoch 6, Loss: 0.9608717679977417\n","Validation Loss: 0.9172666013240814, Accuracy: 58.515625%\n","Epoch 7, Loss: 0.9600563608109951\n","Validation Loss: 0.8975788906216622, Accuracy: 55.78125%\n","Epoch 8, Loss: 0.9425622124224902\n","Validation Loss: 0.9373615071177482, Accuracy: 54.921875%\n","Epoch 9, Loss: 0.9452154040336609\n","Validation Loss: 0.9440957054495811, Accuracy: 54.296875%\n","Epoch 10, Loss: 0.9265390537679196\n","Validation Loss: 0.8854614362120629, Accuracy: 56.953125%\n"]}],"source":["# Number of epochs to train for\n","num_epochs = 10\n","\n","# train Vision Transformer model\n","for epoch in range(num_epochs):\n","    vit_model.train()  # Set the model to training mode\n","    running_loss = 0.0\n","    \n","    # torch.uint8 is supported on the CPU only, so we need to move the input and label tensors to the correct device\n","    for inputs, labels in trainloader:\n","        # Move the input and label tensors to the correct device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        \n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","        \n","        # Forward pass\n","        outputs = vit_model(inputs)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item()\n","    \n","    # Print statistics\n","    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n","    \n","    # Validation loss\n","    vit_model.eval()  # Set the model to evaluation mode\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in valloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = vit_model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    \n","    print(f'Validation Loss: {val_loss / len(valloader)}, Accuracy: {100 * correct / total}%')\n","# Save the model\n","torch.save(vit_model.state_dict(), '/kaggle/working/alzheimer_vit_model.pth')"]},{"cell_type":"markdown","metadata":{},"source":["## Model Evaluation"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T16:32:55.752068Z","iopub.status.busy":"2024-02-18T16:32:55.751240Z","iopub.status.idle":"2024-02-18T16:32:56.102803Z","shell.execute_reply":"2024-02-18T16:32:56.101693Z","shell.execute_reply.started":"2024-02-18T16:32:55.752025Z"},"trusted":true},"outputs":[],"source":["def plot_loss(train_losses, val_losses, title='Loss Plot'):\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(train_losses, label='Train Loss')\n","    plt.plot(val_losses, label='Validation Loss')\n","    plt.title(title)\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def evaluate_model(model, dataloader, device, criterion):\n","    model.eval()  # Set model to evaluate mode\n","    val_losses = []\n","    all_preds = []\n","    all_labels = []\n","    \n","    with torch.no_grad():\n","        for inputs, labels in dataloader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            \n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_losses.append(loss.item())\n","            \n","            _, preds = torch.max(outputs, 1)\n","            all_preds.extend(preds.view(-1).cpu().numpy())\n","            all_labels.extend(labels.view(-1).cpu().numpy())\n","\n","    # Calculate overall metrics\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n","    cm = confusion_matrix(all_labels, all_preds)\n","\n","    # Plot loss and confusion matrix\n","    plot_loss([], val_losses, title='Validation Loss')  # Pass training losses if available\n","    plot_confusion_matrix(cm, classes=['Mild_Demented', 'Moderate_Demented', 'Non_Demented', 'Very_Mild_Demented'], title='Confusion Matrix')\n","    \n","    # Print metrics\n","    print(f'Accuracy: {accuracy:.4f}')\n","    print(f'Precision: {precision:.4f}')\n","    print(f'Recall: {recall:.4f}')\n","    print(f'F1 Score: {f1:.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluating ResNet\n","evaluate_model(model, valloader, device, criterion)\n","\n","# Evaluating  EfficientNet Model\n","evaluate_model(efficientnet_model, valloader, device, criterion)\n","\n","# Evaluating Vision Transformer\n","evaluate_model(vit_model, valloader, device, criterion)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":2029496,"sourceId":3364939,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":4}
